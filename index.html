<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>AOS Avatar</title>
<style>
  :root { --bg:#0b1020; --card:#121933; --accent:#5eead4; --text:#e6e8ef; }
  body { margin:0; background:var(--bg); color:var(--text); font:500 16px/1.4 ui-sans-serif,system-ui; display:grid; place-items:center; min-height:100dvh; }
  .card { width:min(420px,92vw); padding:20px; border-radius:18px; background:var(--card); box-shadow:0 12px 32px rgba(0,0,0,.35) }
  .row { display:flex; align-items:center; gap:12px; justify-content:space-between }
  .btn { appearance:none; border:0; padding:10px 14px; border-radius:12px; background:var(--accent); color:#041316; font-weight:700; cursor:pointer }
  .btn:disabled { opacity:.6; cursor:not-allowed }
  .small { opacity:.75; font-size:12px }
  .face { width:210px; height:210px; margin:6px auto 16px; display:block; }
  .eye { fill:#e6e8ef }
  .mouth { fill:#e6e8ef; transform-origin:50% 50%; transition:transform 80ms linear }
  .ring { fill:none; stroke:var(--accent); stroke-width:3; opacity:.4 }
  .meter { height:6px; border-radius:999px; background:#0f1733; overflow:hidden; margin-top:10px }
  .bar { height:100%; width:0%; background:var(--accent); transition:width 80ms linear }
</style>
</head>
<body>
  <div class="card">
    <svg class="face" viewBox="0 0 220 220" aria-hidden="true" id="face">
      <circle cx="110" cy="110" r="104" class="ring"/>
      <circle cx="75"  cy="95"  r="8"   class="eye"/>
      <circle cx="145" cy="95"  r="8"   class="eye"/>
      <rect id="mouth" class="mouth" x="80" y="140" rx="12" ry="12" width="60" height="14"/>
    </svg>

    <div class="row">
      <button id="startBtn" class="btn">Start</button>
      <div class="small" id="status">idle</div>
    </div>
    <div class="meter"><div id="meterBar" class="bar"></div></div>

    <!-- Assistant voice goes here -->
    <audio id="assistantAudio" autoplay playsinline crossorigin="anonymous"></audio>

    <p class="small" style="margin-top:12px">
      Tip: pass <code>?sid=USER123&configId=YOUR_CONFIG_ID</code> in the iframe URL.
    </p>
  </div>

<script>
/* ========= Endpoints & Config ========= */
const MAKE_GET_PROGRESS_URL = 'https://hook.us2.make.com/4acwokdxb0jif73t9miplk2b4fbi556d';
const MAKE_SESSION_URL      = 'https://hook.us2.make.com/6b6twrhnkm75rfiv38jcf2414uz2rqfg';
const DEFAULT_CONFIG_ID     = 'cab67954-6a4e-448e-aa62-50eab156f3a0'; // your Hume config

/* ========= Query params from iframe ========= */
const qs    = new URLSearchParams(location.search);
const sid   = qs.get('sid')      || 'demo-user';     // replace with required later
const cfgId = qs.get('configId') || DEFAULT_CONFIG_ID;
const vid   = qs.get('voiceId')  || '';

/* ========= Elements ========= */
const $status = document.getElementById('status');
const $start  = document.getElementById('startBtn');
const $mouth  = document.getElementById('mouth');
const $bar    = document.getElementById('meterBar');
const $audio  = document.getElementById('assistantAudio');

/* ========= Audio visualizer (animates mouth with volume) ========= */
let audioCtx, analyser, dataArray, rafId;

function attachAnalyserTo(elementOrStream) {
  audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
  analyser = audioCtx.createAnalyser();
  analyser.fftSize = 1024;
  const src = elementOrStream instanceof MediaStream
    ? audioCtx.createMediaStreamSource(elementOrStream)
    : audioCtx.createMediaElementSource(elementOrStream);
  src.connect(analyser).connect(audioCtx.destination);
  dataArray = new Uint8Array(analyser.frequencyBinCount);
  tick();
}
function tick(){
  analyser.getByteFrequencyData(dataArray);
  let sum = 0; for (let i=4;i<32;i++) sum += dataArray[i];
  const avg = sum / 28;                 // 0..255
  const gain = Math.min(1, avg/80);     // normalize
  $mouth.style.transform = `scale(${1+gain*0.9}, ${1+gain*0.3})`;
  $bar.style.width = `${Math.round(gain*100)}%`;
  rafId = requestAnimationFrame(tick);
}

/* ========= Tool endpoints (Make) ========= */
async function callMakeGetProgress({ studentId, courseId }) {
  const u = new URL(MAKE_GET_PROGRESS_URL);
  u.searchParams.set('sid', studentId);
  if (courseId) u.searchParams.set('courseId', courseId);
  const r = await fetch(u.toString(), { method: 'GET' });
  if (!r.ok) throw new Error('get_progress failed');
  return r.json(); // { studentId, courses: [...] }
}

/* ========= Tool-call router (Hume -> Make -> Hume) ========= */
async function onToolCall(name, params, respond) {
  try {
    if (name === 'get_student_progress') {
      const data = await callMakeGetProgress({
        studentId: params.studentId || sid,
        courseId : params.courseId  || ''
      });
      await respond(data);
      return;
    }

    // TODO: add other tools later (kb_search, create_reminder, log_event)
    await respond({ ok: true });
  } catch (err) {
    console.error('tool error', err);
    await respond({ error: String(err) });
  }
}

/* ========= Hooks called when assistant audio is available ========= */
function setAssistantAudioStream(mediaStream){
  $audio.srcObject = mediaStream;
  attachAnalyserTo(mediaStream);
  $status.textContent = 'connected';
}

/* ========= Hume connector (SDK-friendly; falls back gracefully) ========= */
async function connectToHume(wsUrl){
  // If Hume SDK is available globally, use it. Otherwise show a message.
  if (window.HumeClient?.connect) {
    const mic = await navigator.mediaDevices.getUserMedia({ audio: true });
    const client = await window.HumeClient.connect(wsUrl); // hypothetical SDK entry
    // send mic to Hume
    await client.sendUserAudio(mic);
    // get assistant audio stream, animate mouth
    const assistantStream = await client.getAssistantAudioStream();
    setAssistantAudioStream(assistantStream);

    // tool calls
    client.on('tool_call', async (ev) => {
      // ev: { id, name, parameters (json string) }
      let params = {};
      try { params = typeof ev.parameters === 'string' ? JSON.parse(ev.parameters) : (ev.parameters || {}); } catch {}
      const respond = (payload) => client.toolRespond(ev.id, payload);
      await onToolCall(ev.name, params, respond);
    });

    // status
    client.on('connected', () => $status.textContent = 'connected ✓');
    client.on('disconnected', () => $status.textContent = 'disconnected');

    return;
  }

  // Fallback if SDK isn’t loaded yet
  console.warn('HumeClient SDK not found. Include their web SDK to enable live chat.');
  $status.textContent = 'session OK — add Hume SDK to talk';
}

/* ========= Start button ========= */
$start.addEventListener('click', async () => {
  try {
    $start.disabled = true;
    $status.textContent = 'auth…';

    // 1) Get short-lived wsUrl from Make /hume/session
    const u = new URL(MAKE_SESSION_URL);
    u.searchParams.set('sid', sid);
    if (cfgId) u.searchParams.set('configId', cfgId);
    if (vid)   u.searchParams.set('voiceId',  vid);

    const res = await fetch(u.toString());
    if (!res.ok) throw new Error('session fetch failed');
    const { wsUrl } = await res.json();

    console.log('Hume session OK:', { wsUrl });
    $status.textContent = 'connecting…';

    // 2) Connect to Hume (if SDK present) and wire tools/audio
    await connectToHume(wsUrl);

  } catch (e) {
    console.error(e);
    $status.textContent = 'session error (check webhook URL/CORS)';
    $start.disabled = false;
  }
});

/* ========= Demo beep on face click (still handy for testing) ========= */
document.getElementById('face').addEventListener('click', async () => {
  try {
    audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
    if (audioCtx.state === 'suspended') await audioCtx.resume();
    if (!analyser) { analyser = audioCtx.createAnalyser(); analyser.fftSize = 1024; dataArray = new Uint8Array(analyser.frequencyBinCount); }

    const osc = audioCtx.createOscillator();
    const gain = audioCtx.createGain();
    osc.type = 'sine'; osc.frequency.value = 880; gain.gain.value = 0.0001;
    osc.connect(gain); gain.connect(analyser); analyser.connect(audioCtx.destination);
    if (!rafId) tick();

    const now = audioCtx.currentTime;
    osc.start(now);
    gain.gain.exponentialRampToValueAtTime(0.2, now + 0.01);
    gain.gain.exponentialRampToValueAtTime(0.0001, now + 0.25);
    osc.stop(now + 0.30);
    $status.textContent = 'demo beep ✓';
  } catch (err) {
    console.error(err);
    $status.textContent = 'could not play (try clicking Start first)';
  }
});
</script>
</body>
</html>
